{"ast":null,"code":"import TLError from \"../core/TLError\";\nimport { fetchCSV } from '../core/CSV';\nimport { trim, isEmptyObject, mergeData, trace } from \"../core/Util\";\n/**\n * Given a Google Sheets URL or a bare spreadsheet key, return a URL expected\n * to retrieve a CSV file, assuming the Sheets doc has been \"published to the web\".\n * No checking for the actual availability is done.\n * @param {string} url_or_key \n */\n\nexport function makeGoogleCSVURL(url_or_key) {\n  url_or_key = url_or_key.trim();\n\n  if (url_or_key.match(/^[a-zA-Z0-9-_]+$/)) {\n    // key pattern from https://developers.google.com/sheets/api/guides/concepts#spreadsheet_id\n    return `https://docs.google.com/spreadsheets/d/${url_or_key}/pub?output=csv`;\n  }\n\n  if (url_or_key.startsWith('https://docs.google.com/spreadsheets/')) {\n    if (url_or_key.match(/\\/pub\\?output=csv$/)) return url_or_key;\n    let parsed = new URL(url_or_key);\n    let params = new URLSearchParams(parsed.search);\n    params.set('output', 'csv');\n\n    if (params.get('gid')) {\n      params.set('single', 'true');\n    }\n\n    parsed.search = `?${params.toString()}`;\n    let base_path = parsed.pathname.substr(0, parsed.pathname.lastIndexOf('/'));\n    parsed.pathname = `${base_path}/pub`;\n    return parsed.toString();\n  }\n\n  throw new TLError('invalid_url_err', url_or_key);\n}\n/**\n * Given a Google Sheets URL (or mere document ID), read the data and return\n * a Timeline JSON file suitable for instantiating a timeline.\n * \n * @param {string} url \n */\n\nexport async function readGoogleAsCSV(url, sheets_proxy) {\n  let rows = [];\n  url = makeGoogleCSVURL(url);\n  let error = null;\n  await fetchCSV({\n    url: `${sheets_proxy}${url}`\n  }).then(d => {\n    rows = d;\n  }).catch(error_json => {\n    if (error_json.proxy_err_code == 'response_not_csv') {\n      throw new TLError('Timeline could not read the data for your timeline. Make sure you have published it to the web.');\n    } // throw new TLError(error_json.message)\n\n  });\n  let timeline_config = {\n    'events': [],\n    'errors': [],\n    'warnings': [],\n    'eras': []\n  };\n  rows.forEach((row, i) => {\n    try {\n      if (!isEmptyObject(row)) {// let event = extractEventFromCSVObject(row)\n        // handleRow(event, timeline_config)\n      }\n    } catch (e) {\n      if (e.constructor == TLError) {\n        timeline_config.errors.push(e);\n      } else {\n        if (e.message) {\n          e = e.message;\n        }\n\n        let label = row['Headline'] || i;\n        timeline_config.errors.push(e + `[${label}]`);\n      }\n    }\n  });\n  console.log(timeline_config);\n  return timeline_config;\n}\n\nfunction handleRow(event, timeline_config) {\n  var row_type = 'event';\n\n  if (typeof event.type != 'undefined') {\n    row_type = event.type;\n    delete event.type;\n  }\n\n  if (row_type == 'title') {\n    if (!timeline_config.title) {\n      timeline_config.title = event;\n    } else {\n      timeline_config.warnings.push(\"Multiple title slides detected.\");\n      timeline_config.events.push(event);\n    }\n  } else if (row_type == 'era') {\n    timeline_config.eras.push(event);\n  } else {\n    timeline_config.events.push(event);\n  }\n} // function extractEventFromCSVObject(orig_row) {\n//     let row = {}\n//     Object.keys(orig_row).forEach(k => {\n//         row[k] = trim(orig_row[k]) // get rid of white-space and reduce all-blank cells to empty strings\n//     })\n//     var d = {\n//         media: {\n//             caption: row['Media Caption'] || '',\n//             credit: row['Media Credit'] || '',\n//             url: row['Media'] || '',\n//             thumbnail: row['Media Thumbnail'] || ''\n//         },\n//         text: {\n//             headline: row['Headline'] || '',\n//             text: row['Text'] || ''\n//         },\n//         display_date: row['Display Date'] || '', // only in v3 but no problem\n//         group: row['Group'] || row['Tag'] || '', // small diff between v1 and v3 sheets\n//         background: interpretBackground(row['Background']), // only in v3 but no problem\n//         type: row['Type'] || ''\n//     }\n//     if (Object.keys(row).includes('Start Date') || Object.keys(row).includes('End Date')) {\n//         // V1 date handling\n//         if (row['Start Date']) {\n//             d.start_date = parseDate(row['Start Date'])\n//         }\n//         if (row['End Date']) {\n//             d.end_date = parseDate(row['End Date'])\n//         }\n//     } else {\n//         // V3 date handling\n//         // every date must have at least a year to be valid.\n//         if (row['Year']) {\n//             d.start_date = {\n//                 year: clean_integer(row['Year']),\n//                 month: clean_integer(row['Month']) || '',\n//                 day: clean_integer(row['Day']) || ''\n//             }\n//         }\n//         if (row['End Year']) {\n//             d.end_date = {\n//                 year: clean_integer(row['End Year']) || '',\n//                 month: clean_integer(row['End Month']) || '',\n//                 day: clean_integer(row['End Day']) || ''\n//             }\n//         }\n//         if (row['Time']) {\n//             if (d.start_date) {\n//                 mergeData(d.start_date, parseTime(row['Time']));\n//             } else {\n//                 throw new TLError(\"invalid_start_time_without_date\")\n//             }\n//         }\n//         if (row['End Time']) {\n//             if (d.end_date) {\n//                 mergeData(d.end_date, parseTime(row['End Time']));\n//             } else {\n//                 throw new TLError(\"invalid_end_time_without_date\")\n//             }\n//         }\n//         if (d.start_date && !validDateConfig(d.start_date)) {\n//             throw new TLError(\"invalid_date_err\")\n//         }\n//         if (d.end_date && !validDateConfig(d.end_date)) {\n//             throw new TLError(\"invalid_date_err\")\n//         }\n//     }\n//     return d\n// }","map":{"version":3,"sources":["/Users/nanyang/AY20S2/CS9080/LookingGlass/lookingglass/src/core/Config.js"],"names":["TLError","fetchCSV","trim","isEmptyObject","mergeData","trace","makeGoogleCSVURL","url_or_key","match","startsWith","parsed","URL","params","URLSearchParams","search","set","get","toString","base_path","pathname","substr","lastIndexOf","readGoogleAsCSV","url","sheets_proxy","rows","error","then","d","catch","error_json","proxy_err_code","timeline_config","forEach","row","i","e","constructor","errors","push","message","label","console","log","handleRow","event","row_type","type","title","warnings","events","eras"],"mappings":"AAAA,OAAOA,OAAP,MAAoB,iBAApB;AACA,SAASC,QAAT,QAAyB,aAAzB;AACA,SAASC,IAAT,EAAeC,aAAf,EAA8BC,SAA9B,EAAyCC,KAAzC,QAAsD,cAAtD;AAIA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASC,gBAAT,CAA0BC,UAA1B,EAAsC;AACzCA,EAAAA,UAAU,GAAGA,UAAU,CAACL,IAAX,EAAb;;AACA,MAAIK,UAAU,CAACC,KAAX,CAAiB,kBAAjB,CAAJ,EAA0C;AACtC;AACA,WAAQ,0CAAyCD,UAAW,iBAA5D;AACH;;AAED,MAAIA,UAAU,CAACE,UAAX,CAAsB,uCAAtB,CAAJ,EAAoE;AAChE,QAAIF,UAAU,CAACC,KAAX,CAAiB,oBAAjB,CAAJ,EAA4C,OAAOD,UAAP;AAC5C,QAAIG,MAAM,GAAG,IAAIC,GAAJ,CAAQJ,UAAR,CAAb;AACA,QAAIK,MAAM,GAAG,IAAIC,eAAJ,CAAoBH,MAAM,CAACI,MAA3B,CAAb;AACAF,IAAAA,MAAM,CAACG,GAAP,CAAW,QAAX,EAAqB,KAArB;;AACA,QAAIH,MAAM,CAACI,GAAP,CAAW,KAAX,CAAJ,EAAuB;AACnBJ,MAAAA,MAAM,CAACG,GAAP,CAAW,QAAX,EAAqB,MAArB;AACH;;AACDL,IAAAA,MAAM,CAACI,MAAP,GAAiB,IAAGF,MAAM,CAACK,QAAP,EAAkB,EAAtC;AACA,QAAIC,SAAS,GAAGR,MAAM,CAACS,QAAP,CAAgBC,MAAhB,CAAuB,CAAvB,EAA0BV,MAAM,CAACS,QAAP,CAAgBE,WAAhB,CAA4B,GAA5B,CAA1B,CAAhB;AACAX,IAAAA,MAAM,CAACS,QAAP,GAAmB,GAAED,SAAU,MAA/B;AACA,WAAOR,MAAM,CAACO,QAAP,EAAP;AACH;;AACD,QAAM,IAAIjB,OAAJ,CAAY,iBAAZ,EAA+BO,UAA/B,CAAN;AACH;AAED;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,eAAee,eAAf,CAA+BC,GAA/B,EAAoCC,YAApC,EAAkD;AAErD,MAAIC,IAAI,GAAG,EAAX;AAEAF,EAAAA,GAAG,GAAGjB,gBAAgB,CAACiB,GAAD,CAAtB;AACA,MAAIG,KAAK,GAAG,IAAZ;AAEA,QAAMzB,QAAQ,CAAC;AACXsB,IAAAA,GAAG,EAAG,GAAEC,YAAa,GAAED,GAAI;AADhB,GAAD,CAAR,CAEHI,IAFG,CAEEC,CAAC,IAAI;AACTH,IAAAA,IAAI,GAAGG,CAAP;AACH,GAJK,EAIHC,KAJG,CAIGC,UAAU,IAAI;AACnB,QAAIA,UAAU,CAACC,cAAX,IAA6B,kBAAjC,EAAqD;AACjD,YAAM,IAAI/B,OAAJ,CAAY,iGAAZ,CAAN;AACH,KAHkB,CAInB;;AACH,GATK,CAAN;AAWA,MAAIgC,eAAe,GAAG;AAAE,cAAU,EAAZ;AAAgB,cAAU,EAA1B;AAA8B,gBAAY,EAA1C;AAA8C,YAAQ;AAAtD,GAAtB;AAEAP,EAAAA,IAAI,CAACQ,OAAL,CAAa,CAACC,GAAD,EAAMC,CAAN,KAAY;AACrB,QAAI;AACA,UAAI,CAAChC,aAAa,CAAC+B,GAAD,CAAlB,EAAyB,CACrB;AACA;AACH;AACJ,KALD,CAKE,OAAOE,CAAP,EAAU;AACR,UAAIA,CAAC,CAACC,WAAF,IAAiBrC,OAArB,EAA8B;AAC1BgC,QAAAA,eAAe,CAACM,MAAhB,CAAuBC,IAAvB,CAA4BH,CAA5B;AACH,OAFD,MAEO;AACH,YAAIA,CAAC,CAACI,OAAN,EAAe;AACXJ,UAAAA,CAAC,GAAGA,CAAC,CAACI,OAAN;AACH;;AACD,YAAIC,KAAK,GAAGP,GAAG,CAAC,UAAD,CAAH,IAAmBC,CAA/B;AACAH,QAAAA,eAAe,CAACM,MAAhB,CAAuBC,IAAvB,CAA4BH,CAAC,GAAI,IAAGK,KAAM,GAA1C;AACH;AACJ;AACJ,GAjBD;AAkBAC,EAAAA,OAAO,CAACC,GAAR,CAAYX,eAAZ;AACA,SAAOA,eAAP;AACH;;AAED,SAASY,SAAT,CAAmBC,KAAnB,EAA0Bb,eAA1B,EAA2C;AACvC,MAAIc,QAAQ,GAAG,OAAf;;AACA,MAAI,OAAOD,KAAK,CAACE,IAAb,IAAsB,WAA1B,EAAuC;AACnCD,IAAAA,QAAQ,GAAGD,KAAK,CAACE,IAAjB;AACA,WAAOF,KAAK,CAACE,IAAb;AACH;;AACD,MAAID,QAAQ,IAAI,OAAhB,EAAyB;AACrB,QAAI,CAACd,eAAe,CAACgB,KAArB,EAA4B;AACxBhB,MAAAA,eAAe,CAACgB,KAAhB,GAAwBH,KAAxB;AACH,KAFD,MAEO;AACHb,MAAAA,eAAe,CAACiB,QAAhB,CAAyBV,IAAzB,CAA8B,iCAA9B;AACAP,MAAAA,eAAe,CAACkB,MAAhB,CAAuBX,IAAvB,CAA4BM,KAA5B;AACH;AACJ,GAPD,MAOO,IAAIC,QAAQ,IAAI,KAAhB,EAAuB;AAC1Bd,IAAAA,eAAe,CAACmB,IAAhB,CAAqBZ,IAArB,CAA0BM,KAA1B;AACH,GAFM,MAEA;AACHb,IAAAA,eAAe,CAACkB,MAAhB,CAAuBX,IAAvB,CAA4BM,KAA5B;AACH;AACJ,C,CAED;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAGA;AAEA;AACA","sourcesContent":["import TLError from \"../core/TLError\"\nimport { fetchCSV } from '../core/CSV';\nimport { trim, isEmptyObject, mergeData, trace } from \"../core/Util\";\n\n\n\n/**\n * Given a Google Sheets URL or a bare spreadsheet key, return a URL expected\n * to retrieve a CSV file, assuming the Sheets doc has been \"published to the web\".\n * No checking for the actual availability is done.\n * @param {string} url_or_key \n */\nexport function makeGoogleCSVURL(url_or_key) {\n    url_or_key = url_or_key.trim()\n    if (url_or_key.match(/^[a-zA-Z0-9-_]+$/)) {\n        // key pattern from https://developers.google.com/sheets/api/guides/concepts#spreadsheet_id\n        return `https://docs.google.com/spreadsheets/d/${url_or_key}/pub?output=csv`\n    }\n\n    if (url_or_key.startsWith('https://docs.google.com/spreadsheets/')) {\n        if (url_or_key.match(/\\/pub\\?output=csv$/)) return url_or_key\n        let parsed = new URL(url_or_key)\n        let params = new URLSearchParams(parsed.search)\n        params.set('output', 'csv')\n        if (params.get('gid')) {\n            params.set('single', 'true')\n        }\n        parsed.search = `?${params.toString()}`\n        let base_path = parsed.pathname.substr(0, parsed.pathname.lastIndexOf('/'))\n        parsed.pathname = `${base_path}/pub`\n        return parsed.toString()\n    }\n    throw new TLError('invalid_url_err', url_or_key);\n}\n\n/**\n * Given a Google Sheets URL (or mere document ID), read the data and return\n * a Timeline JSON file suitable for instantiating a timeline.\n * \n * @param {string} url \n */\nexport async function readGoogleAsCSV(url, sheets_proxy) {\n\n    let rows = []\n\n    url = makeGoogleCSVURL(url)\n    let error = null;\n\n    await fetchCSV({\n        url: `${sheets_proxy}${url}`,\n    }).then(d => {\n        rows = d;\n    }).catch(error_json => {\n        if (error_json.proxy_err_code == 'response_not_csv') {\n            throw new TLError('Timeline could not read the data for your timeline. Make sure you have published it to the web.')\n        }\n        // throw new TLError(error_json.message)\n    })\n\n    let timeline_config = { 'events': [], 'errors': [], 'warnings': [], 'eras': [] }\n\n    rows.forEach((row, i) => {\n        try {\n            if (!isEmptyObject(row)) {\n                // let event = extractEventFromCSVObject(row)\n                // handleRow(event, timeline_config)\n            }\n        } catch (e) {\n            if (e.constructor == TLError) {\n                timeline_config.errors.push(e);\n            } else {\n                if (e.message) {\n                    e = e.message;\n                }\n                let label = row['Headline'] || i\n                timeline_config.errors.push(e + `[${label}]`);\n            }\n        }\n    });\n    console.log(timeline_config);\n    return timeline_config\n}\n\nfunction handleRow(event, timeline_config) {\n    var row_type = 'event';\n    if (typeof(event.type) != 'undefined') {\n        row_type = event.type;\n        delete event.type;\n    }\n    if (row_type == 'title') {\n        if (!timeline_config.title) {\n            timeline_config.title = event;\n        } else {\n            timeline_config.warnings.push(\"Multiple title slides detected.\");\n            timeline_config.events.push(event);\n        }\n    } else if (row_type == 'era') {\n        timeline_config.eras.push(event);\n    } else {\n        timeline_config.events.push(event);\n    }\n}\n\n// function extractEventFromCSVObject(orig_row) {\n\n//     let row = {}\n//     Object.keys(orig_row).forEach(k => {\n//         row[k] = trim(orig_row[k]) // get rid of white-space and reduce all-blank cells to empty strings\n//     })\n\n//     var d = {\n//         media: {\n//             caption: row['Media Caption'] || '',\n//             credit: row['Media Credit'] || '',\n//             url: row['Media'] || '',\n//             thumbnail: row['Media Thumbnail'] || ''\n//         },\n//         text: {\n//             headline: row['Headline'] || '',\n//             text: row['Text'] || ''\n//         },\n//         display_date: row['Display Date'] || '', // only in v3 but no problem\n//         group: row['Group'] || row['Tag'] || '', // small diff between v1 and v3 sheets\n//         background: interpretBackground(row['Background']), // only in v3 but no problem\n//         type: row['Type'] || ''\n//     }\n\n//     if (Object.keys(row).includes('Start Date') || Object.keys(row).includes('End Date')) {\n//         // V1 date handling\n//         if (row['Start Date']) {\n//             d.start_date = parseDate(row['Start Date'])\n//         }\n//         if (row['End Date']) {\n//             d.end_date = parseDate(row['End Date'])\n//         }\n//     } else {\n//         // V3 date handling\n//         // every date must have at least a year to be valid.\n//         if (row['Year']) {\n//             d.start_date = {\n//                 year: clean_integer(row['Year']),\n//                 month: clean_integer(row['Month']) || '',\n//                 day: clean_integer(row['Day']) || ''\n//             }\n//         }\n//         if (row['End Year']) {\n//             d.end_date = {\n//                 year: clean_integer(row['End Year']) || '',\n//                 month: clean_integer(row['End Month']) || '',\n//                 day: clean_integer(row['End Day']) || ''\n//             }\n//         }\n\n//         if (row['Time']) {\n//             if (d.start_date) {\n//                 mergeData(d.start_date, parseTime(row['Time']));\n//             } else {\n//                 throw new TLError(\"invalid_start_time_without_date\")\n//             }\n//         }\n\n//         if (row['End Time']) {\n//             if (d.end_date) {\n//                 mergeData(d.end_date, parseTime(row['End Time']));\n//             } else {\n//                 throw new TLError(\"invalid_end_time_without_date\")\n//             }\n//         }\n\n//         if (d.start_date && !validDateConfig(d.start_date)) {\n//             throw new TLError(\"invalid_date_err\")\n//         }\n\n//         if (d.end_date && !validDateConfig(d.end_date)) {\n//             throw new TLError(\"invalid_date_err\")\n//         }\n\n\n//     }\n\n//     return d\n// }\n"]},"metadata":{},"sourceType":"module"}