{"ast":null,"code":"import TLError from \"../core/TLError\";\nimport { fetchCSV } from '../core/CSV';\nimport { trim, isEmptyObject, mergeData, trace } from \"../core/Util\";\n/**\r\n * Given a Google Sheets URL or a bare spreadsheet key, return a URL expected\r\n * to retrieve a CSV file, assuming the Sheets doc has been \"published to the web\".\r\n * No checking for the actual availability is done.\r\n * @param {string} url_or_key \r\n */\n\nexport function makeGoogleCSVURL(url_or_key) {\n  url_or_key = url_or_key.trim();\n\n  if (url_or_key.match(/^[a-zA-Z0-9-_]+$/)) {\n    // key pattern from https://developers.google.com/sheets/api/guides/concepts#spreadsheet_id\n    return `https://docs.google.com/spreadsheets/d/${url_or_key}/pub?output=csv`;\n  }\n\n  if (url_or_key.startsWith('https://docs.google.com/spreadsheets/')) {\n    if (url_or_key.match(/\\/pub\\?output=csv$/)) return url_or_key;\n    let parsed = new URL(url_or_key);\n    let params = new URLSearchParams(parsed.search);\n    params.set('output', 'csv');\n\n    if (params.get('gid')) {\n      params.set('single', 'true');\n    }\n\n    parsed.search = `?${params.toString()}`;\n    let base_path = parsed.pathname.substr(0, parsed.pathname.lastIndexOf('/'));\n    parsed.pathname = `${base_path}/pub`;\n    return parsed.toString();\n  }\n\n  throw new TLError('invalid_url_err', url_or_key);\n} // /**\n//  * Given a Google Sheets URL (or mere document ID), read the data and return\n//  * a Timeline JSON file suitable for instantiating a timeline.\n//  * \n//  * @param {string} url \n//  */\n// export async function readGoogleAsCSV(url, sheets_proxy) {\n//     let rows = []\n//     url = makeGoogleCSVURL(url)\n//     let error = null;\n//     await fetchCSV({\n//         url: `${sheets_proxy}${url}`,\n//     }).then(d => {\n//         rows = d;\n//     }).catch(error_json => {\n//         if (error_json.proxy_err_code == 'response_not_csv') {\n//             throw new TLError('Timeline could not read the data for your timeline. Make sure you have published it to the web.')\n//         }\n//         throw new TLError(error_json.message)\n//     })\n//     let timeline_config = { 'events': [], 'errors': [], 'warnings': [], 'eras': [] }\n//     rows.forEach((row, i) => {\n//         try {\n//             if (!isEmptyObject(row)) {\n//                 let event = extractEventFromCSVObject(row)\n//                 handleRow(event, timeline_config)\n//             }\n//         } catch (e) {\n//             if (e.constructor == TLError) {\n//                 timeline_config.errors.push(e);\n//             } else {\n//                 if (e.message) {\n//                     e = e.message;\n//                 }\n//                 let label = row['Headline'] || i\n//                 timeline_config.errors.push(e + `[${label}]`);\n//             }\n//         }\n//     });\n//     console.log(timeline_config);\n//     return timeline_config\n// }","map":{"version":3,"sources":["D:/NTU/Y4S1/CS9080/LookingGlass/lookingglass/src/core/Config.js"],"names":["TLError","fetchCSV","trim","isEmptyObject","mergeData","trace","makeGoogleCSVURL","url_or_key","match","startsWith","parsed","URL","params","URLSearchParams","search","set","get","toString","base_path","pathname","substr","lastIndexOf"],"mappings":"AAAA,OAAOA,OAAP,MAAoB,iBAApB;AACA,SAASC,QAAT,QAAyB,aAAzB;AACA,SAASC,IAAT,EAAeC,aAAf,EAA8BC,SAA9B,EAAyCC,KAAzC,QAAsD,cAAtD;AAIA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASC,gBAAT,CAA0BC,UAA1B,EAAsC;AACzCA,EAAAA,UAAU,GAAGA,UAAU,CAACL,IAAX,EAAb;;AACA,MAAIK,UAAU,CAACC,KAAX,CAAiB,kBAAjB,CAAJ,EAA0C;AACtC;AACA,WAAQ,0CAAyCD,UAAW,iBAA5D;AACH;;AAED,MAAIA,UAAU,CAACE,UAAX,CAAsB,uCAAtB,CAAJ,EAAoE;AAChE,QAAIF,UAAU,CAACC,KAAX,CAAiB,oBAAjB,CAAJ,EAA4C,OAAOD,UAAP;AAC5C,QAAIG,MAAM,GAAG,IAAIC,GAAJ,CAAQJ,UAAR,CAAb;AACA,QAAIK,MAAM,GAAG,IAAIC,eAAJ,CAAoBH,MAAM,CAACI,MAA3B,CAAb;AACAF,IAAAA,MAAM,CAACG,GAAP,CAAW,QAAX,EAAqB,KAArB;;AACA,QAAIH,MAAM,CAACI,GAAP,CAAW,KAAX,CAAJ,EAAuB;AACnBJ,MAAAA,MAAM,CAACG,GAAP,CAAW,QAAX,EAAqB,MAArB;AACH;;AACDL,IAAAA,MAAM,CAACI,MAAP,GAAiB,IAAGF,MAAM,CAACK,QAAP,EAAkB,EAAtC;AACA,QAAIC,SAAS,GAAGR,MAAM,CAACS,QAAP,CAAgBC,MAAhB,CAAuB,CAAvB,EAA0BV,MAAM,CAACS,QAAP,CAAgBE,WAAhB,CAA4B,GAA5B,CAA1B,CAAhB;AACAX,IAAAA,MAAM,CAACS,QAAP,GAAmB,GAAED,SAAU,MAA/B;AACA,WAAOR,MAAM,CAACO,QAAP,EAAP;AACH;;AACD,QAAM,IAAIjB,OAAJ,CAAY,iBAAZ,EAA+BO,UAA/B,CAAN;AACH,C,CAED;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sourcesContent":["import TLError from \"../core/TLError\"\r\nimport { fetchCSV } from '../core/CSV';\r\nimport { trim, isEmptyObject, mergeData, trace } from \"../core/Util\";\r\n\r\n\r\n\r\n/**\r\n * Given a Google Sheets URL or a bare spreadsheet key, return a URL expected\r\n * to retrieve a CSV file, assuming the Sheets doc has been \"published to the web\".\r\n * No checking for the actual availability is done.\r\n * @param {string} url_or_key \r\n */\r\nexport function makeGoogleCSVURL(url_or_key) {\r\n    url_or_key = url_or_key.trim()\r\n    if (url_or_key.match(/^[a-zA-Z0-9-_]+$/)) {\r\n        // key pattern from https://developers.google.com/sheets/api/guides/concepts#spreadsheet_id\r\n        return `https://docs.google.com/spreadsheets/d/${url_or_key}/pub?output=csv`\r\n    }\r\n\r\n    if (url_or_key.startsWith('https://docs.google.com/spreadsheets/')) {\r\n        if (url_or_key.match(/\\/pub\\?output=csv$/)) return url_or_key\r\n        let parsed = new URL(url_or_key)\r\n        let params = new URLSearchParams(parsed.search)\r\n        params.set('output', 'csv')\r\n        if (params.get('gid')) {\r\n            params.set('single', 'true')\r\n        }\r\n        parsed.search = `?${params.toString()}`\r\n        let base_path = parsed.pathname.substr(0, parsed.pathname.lastIndexOf('/'))\r\n        parsed.pathname = `${base_path}/pub`\r\n        return parsed.toString()\r\n    }\r\n    throw new TLError('invalid_url_err', url_or_key);\r\n}\r\n\r\n// /**\r\n//  * Given a Google Sheets URL (or mere document ID), read the data and return\r\n//  * a Timeline JSON file suitable for instantiating a timeline.\r\n//  * \r\n//  * @param {string} url \r\n//  */\r\n// export async function readGoogleAsCSV(url, sheets_proxy) {\r\n\r\n//     let rows = []\r\n\r\n//     url = makeGoogleCSVURL(url)\r\n//     let error = null;\r\n\r\n//     await fetchCSV({\r\n//         url: `${sheets_proxy}${url}`,\r\n//     }).then(d => {\r\n//         rows = d;\r\n//     }).catch(error_json => {\r\n//         if (error_json.proxy_err_code == 'response_not_csv') {\r\n//             throw new TLError('Timeline could not read the data for your timeline. Make sure you have published it to the web.')\r\n//         }\r\n//         throw new TLError(error_json.message)\r\n//     })\r\n\r\n//     let timeline_config = { 'events': [], 'errors': [], 'warnings': [], 'eras': [] }\r\n\r\n//     rows.forEach((row, i) => {\r\n//         try {\r\n//             if (!isEmptyObject(row)) {\r\n//                 let event = extractEventFromCSVObject(row)\r\n//                 handleRow(event, timeline_config)\r\n//             }\r\n//         } catch (e) {\r\n//             if (e.constructor == TLError) {\r\n//                 timeline_config.errors.push(e);\r\n//             } else {\r\n//                 if (e.message) {\r\n//                     e = e.message;\r\n//                 }\r\n//                 let label = row['Headline'] || i\r\n//                 timeline_config.errors.push(e + `[${label}]`);\r\n//             }\r\n//         }\r\n//     });\r\n//     console.log(timeline_config);\r\n//     return timeline_config\r\n// }"]},"metadata":{},"sourceType":"module"}